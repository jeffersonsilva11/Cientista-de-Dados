{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a2c32b0",
   "metadata": {},
   "source": [
    "# Passo a Passo para realizar o Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20497e77",
   "metadata": {},
   "source": [
    "**Passo 1**: É necessário preparar o conjunto de dados original.\n",
    "\n",
    "**Passo 2:** Decidir o número de conjunto de dados que queremos gerar usando o método de bootstrap (geralmente representado como *B*).\n",
    "\n",
    "**Passo 3:** Para cada um dos B de conjunto de dados é necessário realizar a amostragem com substituição (bootstrap) do conjunto de dados original, resultando em um novo conjunto de tamanho igual ao original, porém com algumas observações repetidas e outras possivelmente ausentes.\n",
    "\n",
    "**Passo 4:** Após é necessário treinar um modelo em cada um dos *B*. O modelo pode ser qualquer algoritmo de aprendizado de máquina, mas árvores de decisão são comunente usadas.\n",
    "\n",
    "**5º e último passo:** Ao realizar a previsão:\n",
    "\n",
    "- Se o problema for de regressão, é necessário calcular a média das previsões de cada modelo.\n",
    "- Se o problema for classificação, é necessário tomar a classe mais votada como a previsão final (votação por maioria)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04988d9b",
   "metadata": {},
   "source": [
    "# Explicação sobre o Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf93d1",
   "metadata": {},
   "source": [
    "O Bagging, que é uma abreviação de Bootstrap Aggregating, é uma técnica de aprendizado de máquina usada para reduzir a variância em modelos que tendem a se ajustar demais, como as árvores de decisão. A ideia central é treinar múltiplos modelos, cada um em um subconjunto diferente dos dados, e depois combiná-los para obter uma previsão final.\n",
    "\n",
    "A técnica do bootstrap envolve a amostragem do conjunto de dados com substituição, o que significa que algumas observações podem ser repetidas enquanto outras podem não aparecer no subconjunto. Isso introduz diversidade, o que ajuda a combater o ajuste excessivo.\n",
    "\n",
    "Ao combinar previsões de múltiplos modelos, o Bagging suaviza as previsões e torna o modelo final menos sensível a ruídos nos dados de treinamento. Portanto, em vez de confiar em um único modelo, o Bagging leva em consideração a \"opinião\" de vários modelos, tornando as previsões mais robustas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414d9890",
   "metadata": {},
   "source": [
    "# Implementação em Python do Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1272f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo de Bagging: 0.86\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gerar um conjunto de dados de exemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modelo base (árvore de decisão neste exemplo)\n",
    "base_model = DecisionTreeClassifier()\n",
    "\n",
    "# Inicializar o Bagging Classifier\n",
    "bagging = BaggingClassifier(estimator=base_model, n_estimators=100, random_state=42)\n",
    "\n",
    "# Treinar o modelo de Bagging\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred = bagging.predict(X_test)\n",
    "\n",
    "# Avaliar a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo de Bagging: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba099fde",
   "metadata": {},
   "source": [
    "Neste exemplo, usamos a classe BaggingClassifier do scikit-learn, que implementa o Bagging para modelos de classificação. Há também uma versão para regressão chamada BaggingRegressor. A árvore de decisão foi escolhida como o modelo base, mas é possível substituí-la por qualquer outro modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

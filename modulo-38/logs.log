2023-10-30 17:53:02,921:INFO:PyCaret ClassificationExperiment
2023-10-30 17:53:02,921:INFO:Logging name: clf-default-name
2023-10-30 17:53:02,921:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-10-30 17:53:02,921:INFO:version 3.1.0
2023-10-30 17:53:02,921:INFO:Initializing setup()
2023-10-30 17:53:02,921:INFO:self.USI: 31d6
2023-10-30 17:53:02,921:INFO:self._variable_keys: {'pipeline', 'exp_id', 'log_plots_param', 'idx', '_available_plots', 'seed', 'fix_imbalance', 'html_param', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'fold_groups_param', 'X_train', 'logging_param', 'is_multiclass', 'n_jobs_param', 'fold_generator', 'USI', 'X_test', 'target_param', 'exp_name_log', 'y_test', 'y_train', 'y', 'X', 'fold_shuffle_param', '_ml_usecase', 'data'}
2023-10-30 17:53:02,921:INFO:Checking environment
2023-10-30 17:53:02,921:INFO:python_version: 3.8.18
2023-10-30 17:53:02,921:INFO:python_build: ('default', 'Sep 11 2023 08:17:33')
2023-10-30 17:53:02,921:INFO:machine: x86_64
2023-10-30 17:53:02,921:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-10-30 17:53:02,922:INFO:Memory: svmem(total=17179869184, available=7267450880, percent=57.7, used=9044508672, free=1691283456, active=5333045248, inactive=5558734848, wired=3711463424)
2023-10-30 17:53:02,922:INFO:Physical Core: 6
2023-10-30 17:53:02,922:INFO:Logical Core: 12
2023-10-30 17:53:02,922:INFO:Checking libraries
2023-10-30 17:53:02,922:INFO:System:
2023-10-30 17:53:02,922:INFO:    python: 3.8.18 (default, Sep 11 2023, 08:17:33)  [Clang 14.0.6 ]
2023-10-30 17:53:02,922:INFO:executable: /Users/hitss/anaconda3/envs/python38pycaret/bin/python
2023-10-30 17:53:02,922:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-10-30 17:53:02,922:INFO:PyCaret required dependencies:
2023-10-30 17:53:03,006:INFO:                 pip: 23.3
2023-10-30 17:53:03,006:INFO:          setuptools: 68.0.0
2023-10-30 17:53:03,006:INFO:             pycaret: 3.1.0
2023-10-30 17:53:03,006:INFO:             IPython: 8.12.3
2023-10-30 17:53:03,006:INFO:          ipywidgets: 8.1.1
2023-10-30 17:53:03,006:INFO:                tqdm: 4.66.1
2023-10-30 17:53:03,006:INFO:               numpy: 1.23.5
2023-10-30 17:53:03,006:INFO:              pandas: 1.5.3
2023-10-30 17:53:03,006:INFO:              jinja2: 3.1.2
2023-10-30 17:53:03,006:INFO:               scipy: 1.10.1
2023-10-30 17:53:03,006:INFO:              joblib: 1.3.2
2023-10-30 17:53:03,006:INFO:             sklearn: 1.2.2
2023-10-30 17:53:03,006:INFO:                pyod: 1.1.1
2023-10-30 17:53:03,006:INFO:            imblearn: 0.11.0
2023-10-30 17:53:03,006:INFO:   category_encoders: 2.6.3
2023-10-30 17:53:03,007:INFO:            lightgbm: 4.1.0
2023-10-30 17:53:03,007:INFO:               numba: 0.58.1
2023-10-30 17:53:03,007:INFO:            requests: 2.31.0
2023-10-30 17:53:03,007:INFO:          matplotlib: 3.7.3
2023-10-30 17:53:03,007:INFO:          scikitplot: 0.3.7
2023-10-30 17:53:03,007:INFO:         yellowbrick: 1.5
2023-10-30 17:53:03,007:INFO:              plotly: 5.18.0
2023-10-30 17:53:03,007:INFO:    plotly-resampler: Not installed
2023-10-30 17:53:03,007:INFO:             kaleido: 0.2.1
2023-10-30 17:53:03,007:INFO:           schemdraw: 0.15
2023-10-30 17:53:03,007:INFO:         statsmodels: 0.14.0
2023-10-30 17:53:03,007:INFO:              sktime: 0.21.1
2023-10-30 17:53:03,007:INFO:               tbats: 1.1.3
2023-10-30 17:53:03,007:INFO:            pmdarima: 2.0.4
2023-10-30 17:53:03,007:INFO:              psutil: 5.9.6
2023-10-30 17:53:03,007:INFO:          markupsafe: 2.1.3
2023-10-30 17:53:03,007:INFO:             pickle5: Not installed
2023-10-30 17:53:03,007:INFO:         cloudpickle: 3.0.0
2023-10-30 17:53:03,007:INFO:         deprecation: 2.1.0
2023-10-30 17:53:03,007:INFO:              xxhash: 3.4.1
2023-10-30 17:53:03,007:INFO:           wurlitzer: 3.0.3
2023-10-30 17:53:03,007:INFO:PyCaret optional dependencies:
2023-10-30 17:53:03,032:INFO:                shap: Not installed
2023-10-30 17:53:03,032:INFO:           interpret: Not installed
2023-10-30 17:53:03,032:INFO:                umap: Not installed
2023-10-30 17:53:03,032:INFO:     ydata_profiling: Not installed
2023-10-30 17:53:03,032:INFO:  explainerdashboard: Not installed
2023-10-30 17:53:03,032:INFO:             autoviz: Not installed
2023-10-30 17:53:03,032:INFO:           fairlearn: Not installed
2023-10-30 17:53:03,032:INFO:          deepchecks: Not installed
2023-10-30 17:53:03,032:INFO:             xgboost: Not installed
2023-10-30 17:53:03,032:INFO:            catboost: Not installed
2023-10-30 17:53:03,032:INFO:              kmodes: Not installed
2023-10-30 17:53:03,032:INFO:             mlxtend: Not installed
2023-10-30 17:53:03,033:INFO:       statsforecast: Not installed
2023-10-30 17:53:03,033:INFO:        tune_sklearn: Not installed
2023-10-30 17:53:03,033:INFO:                 ray: Not installed
2023-10-30 17:53:03,033:INFO:            hyperopt: Not installed
2023-10-30 17:53:03,033:INFO:              optuna: Not installed
2023-10-30 17:53:03,033:INFO:               skopt: Not installed
2023-10-30 17:53:03,033:INFO:              mlflow: Not installed
2023-10-30 17:53:03,033:INFO:              gradio: Not installed
2023-10-30 17:53:03,033:INFO:             fastapi: Not installed
2023-10-30 17:53:03,033:INFO:             uvicorn: Not installed
2023-10-30 17:53:03,033:INFO:              m2cgen: Not installed
2023-10-30 17:53:03,033:INFO:           evidently: Not installed
2023-10-30 17:53:03,033:INFO:               fugue: Not installed
2023-10-30 17:53:03,033:INFO:           streamlit: Not installed
2023-10-30 17:53:03,033:INFO:             prophet: Not installed
2023-10-30 17:53:03,033:INFO:None
2023-10-30 17:53:03,033:INFO:Set up data.
2023-10-30 17:53:03,590:INFO:Set up folding strategy.
2023-10-30 17:53:03,590:INFO:Set up train/test split.
2023-10-30 17:53:03,959:INFO:Set up index.
2023-10-30 17:53:03,986:INFO:Assigning column types.
2023-10-30 17:53:04,058:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-10-30 17:53:04,106:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,109:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,206:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,246:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-10-30 17:53:04,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-10-30 17:53:04,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,417:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-10-30 17:53:04,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:04,583:INFO:Preparing preprocessing pipeline...
2023-10-30 17:53:04,596:INFO:Set up date feature engineering.
2023-10-30 17:53:04,597:INFO:Set up simple imputation.
2023-10-30 17:53:04,722:INFO:Set up encoding of ordinal features.
2023-10-30 17:53:04,805:INFO:Set up encoding of categorical features.
2023-10-30 17:53:06,185:INFO:Finished creating preprocessing pipeline.
2023-10-30 17:53:06,225:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/0y/g6n919k13q39rb_x1hn4z6f00000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_em...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-10-30 17:53:06,226:INFO:Creating final display dataframe.
2023-10-30 17:53:09,265:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target               mau
2                   Target type            Binary
3           Original data shape      (750000, 15)
4        Transformed data shape      (750000, 34)
5   Transformed train set shape      (525000, 34)
6    Transformed test set shape      (225000, 34)
7              Ordinal features                 3
8              Numeric features                 6
9                 Date features                 1
10         Categorical features                 7
11     Rows with missing values             16.8%
12                   Preprocess              True
13              Imputation type            simple
14           Numeric imputation              mean
15       Categorical imputation              mode
16     Maximum one-hot encoding                25
17              Encoding method              None
18               Fold Generator   StratifiedKFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  clf-default-name
24                          USI              31d6
2023-10-30 17:53:09,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:09,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:09,440:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:09,440:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-10-30 17:53:09,440:INFO:setup() successfully completed in 6.53s...............
2023-10-30 17:53:09,445:INFO:Initializing create_model()
2023-10-30 17:53:09,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-10-30 17:53:09,445:INFO:Checking exceptions
2023-10-30 17:53:09,486:INFO:Importing libraries
2023-10-30 17:53:09,486:INFO:Copying training dataset
2023-10-30 17:53:09,714:INFO:Defining folds
2023-10-30 17:53:09,715:INFO:Declaring metric variables
2023-10-30 17:53:09,719:INFO:Importing untrained model
2023-10-30 17:53:09,723:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-30 17:53:09,731:INFO:Starting cross validation
2023-10-30 17:53:09,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-10-30 17:53:53,575:INFO:Calculating mean and std
2023-10-30 17:53:53,621:INFO:Creating metrics dataframe
2023-10-30 17:53:53,677:INFO:Finalizing model
2023-10-30 17:53:58,983:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-30 17:53:58,991:INFO:[LightGBM] [Info] Number of positive: 41050, number of negative: 483950
2023-10-30 17:53:59,071:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025600 seconds.
2023-10-30 17:53:59,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-30 17:53:59,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-30 17:53:59,072:INFO:[LightGBM] [Info] Total Bins 895
2023-10-30 17:53:59,072:INFO:[LightGBM] [Info] Number of data points in the train set: 525000, number of used features: 32
2023-10-30 17:53:59,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078190 -> initscore=-2.467191
2023-10-30 17:53:59,076:INFO:[LightGBM] [Info] Start training from score -2.467191
2023-10-30 17:54:00,101:INFO:Uploading results into container
2023-10-30 17:54:00,102:INFO:Uploading model into container now
2023-10-30 17:54:00,118:INFO:_master_model_container: 1
2023-10-30 17:54:00,118:INFO:_display_container: 2
2023-10-30 17:54:00,119:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-10-30 17:54:00,119:INFO:create_model() successfully completed......................................
2023-10-30 17:54:00,484:INFO:Initializing evaluate_model()
2023-10-30 17:54:00,484:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2023-10-30 17:54:00,706:INFO:Initializing plot_model()
2023-10-30 17:54:00,706:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, system=True)
2023-10-30 17:54:00,706:INFO:Checking exceptions
2023-10-30 17:54:00,802:INFO:Preloading libraries
2023-10-30 17:54:00,807:INFO:Copying training dataset
2023-10-30 17:54:00,807:INFO:Plot type: pipeline
2023-10-30 17:54:01,043:INFO:Visual Rendered Successfully
2023-10-30 17:54:01,112:INFO:plot_model() successfully completed......................................
2023-10-30 17:54:01,127:INFO:Initializing plot_model()
2023-10-30 17:54:01,127:INFO:plot_model(plot=feature, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, system=True)
2023-10-30 17:54:01,128:INFO:Checking exceptions
2023-10-30 17:54:01,256:INFO:Preloading libraries
2023-10-30 17:54:01,263:INFO:Copying training dataset
2023-10-30 17:54:01,264:INFO:Plot type: feature
2023-10-30 17:54:01,265:WARNING:No coef_ found. Trying feature_importances_
2023-10-30 17:54:01,914:INFO:Visual Rendered Successfully
2023-10-30 17:54:01,990:INFO:plot_model() successfully completed......................................
2023-10-30 17:54:01,997:INFO:Initializing finalize_model()
2023-10-30 17:54:01,997:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-10-30 17:54:01,997:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-10-30 17:54:02,070:INFO:Initializing create_model()
2023-10-30 17:54:02,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8ff9592d90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-10-30 17:54:02,070:INFO:Checking exceptions
2023-10-30 17:54:02,072:INFO:Importing libraries
2023-10-30 17:54:02,072:INFO:Copying training dataset
2023-10-30 17:54:02,082:INFO:Defining folds
2023-10-30 17:54:02,082:INFO:Declaring metric variables
2023-10-30 17:54:02,082:INFO:Importing untrained model
2023-10-30 17:54:02,082:INFO:Declaring custom model
2023-10-30 17:54:02,083:INFO:Light Gradient Boosting Machine Imported successfully
2023-10-30 17:54:02,085:INFO:Cross validation set to False
2023-10-30 17:54:02,085:INFO:Fitting Model
2023-10-30 17:54:09,568:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2023-10-30 17:54:09,580:INFO:[LightGBM] [Info] Number of positive: 58643, number of negative: 691357
2023-10-30 17:54:09,706:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.038102 seconds.
2023-10-30 17:54:09,706:INFO:You can set `force_row_wise=true` to remove the overhead.
2023-10-30 17:54:09,707:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2023-10-30 17:54:09,707:INFO:[LightGBM] [Info] Total Bins 895
2023-10-30 17:54:09,707:INFO:[LightGBM] [Info] Number of data points in the train set: 750000, number of used features: 32
2023-10-30 17:54:09,712:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.078191 -> initscore=-2.467188
2023-10-30 17:54:09,713:INFO:[LightGBM] [Info] Start training from score -2.467188
2023-10-30 17:54:11,777:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-10-30 17:54:11,777:INFO:create_model() successfully completed......................................
2023-10-30 17:54:11,894:INFO:_master_model_container: 1
2023-10-30 17:54:11,894:INFO:_display_container: 2
2023-10-30 17:54:11,944:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-10-30 17:54:11,944:INFO:finalize_model() successfully completed......................................
2023-10-30 17:54:12,156:INFO:Initializing save_model()
2023-10-30 17:54:12,156:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=final_lightgbm_pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/0y/g6n919k13q39rb_x1hn4z6f00000gn/T/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_em...
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['tipo_renda', 'educacao',
                                             'estado_civil',
                                             'tipo_residencia'],
                                    transformer=OneHotEncoder(cols=['tipo_renda',
                                                                    'educacao',
                                                                    'estado_civil',
                                                                    'tipo_residencia'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-10-30 17:54:12,156:INFO:Adding model into prep_pipe
2023-10-30 17:54:12,156:WARNING:Only Model saved as it was a pipeline.
2023-10-30 17:54:12,179:INFO:final_lightgbm_pipeline.pkl saved in current working directory
2023-10-30 17:54:12,244:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(exclude=None, include=['data_ref'],
                                    transformer=ExtractDateTimeFeatures(features=['day',
                                                                                  'month',
                                                                                  'year']))),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'qtd_filhos', 'idade',
                                             'tempo_emprego',
                                             'qt_pessoas_residencia', 'renda'],
                                    transformer=Sim...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-10-30 17:54:12,244:INFO:save_model() successfully completed......................................

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo o arquivo CSV\n",
    "df = pd.read_csv('previsao_de_renda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Unnamed: 0             15000 non-null  int64  \n",
      " 1   data_ref               15000 non-null  object \n",
      " 2   index                  15000 non-null  int64  \n",
      " 3   sexo                   15000 non-null  object \n",
      " 4   posse_de_veiculo       15000 non-null  bool   \n",
      " 5   posse_de_imovel        15000 non-null  bool   \n",
      " 6   qtd_filhos             15000 non-null  int64  \n",
      " 7   tipo_renda             15000 non-null  object \n",
      " 8   educacao               15000 non-null  object \n",
      " 9   estado_civil           15000 non-null  object \n",
      " 10  tipo_residencia        15000 non-null  object \n",
      " 11  idade                  15000 non-null  int64  \n",
      " 12  tempo_emprego          12466 non-null  float64\n",
      " 13  qt_pessoas_residencia  15000 non-null  float64\n",
      " 14  mau                    15000 non-null  bool   \n",
      " 15  renda                  15000 non-null  float64\n",
      "dtypes: bool(3), float64(3), int64(4), object(6)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo as colunas 'Unnamed: 0', 'index' e 'data_ref' \n",
    "df = df.drop(columns=['Unnamed: 0', 'index', 'data_ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo linhas com valores faltantes (NaN)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12466 entries, 0 to 14999\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   sexo                   12466 non-null  object \n",
      " 1   posse_de_veiculo       12466 non-null  bool   \n",
      " 2   posse_de_imovel        12466 non-null  bool   \n",
      " 3   qtd_filhos             12466 non-null  int64  \n",
      " 4   tipo_renda             12466 non-null  object \n",
      " 5   educacao               12466 non-null  object \n",
      " 6   estado_civil           12466 non-null  object \n",
      " 7   tipo_residencia        12466 non-null  object \n",
      " 8   idade                  12466 non-null  int64  \n",
      " 9   tempo_emprego          12466 non-null  float64\n",
      " 10  qt_pessoas_residencia  12466 non-null  float64\n",
      " 11  mau                    12466 non-null  bool   \n",
      " 12  renda                  12466 non-null  float64\n",
      "dtypes: bool(3), float64(3), int64(2), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Verificando as informações da base após as alterações\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a base de dados em variáveis independentes (X) e dependente (y)\n",
    "X = df.drop('renda', axis=1)  # Removendo a coluna de renda para ser nosso y\n",
    "y = df['renda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo a base de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento (X): (9349, 12)\n",
      "Treinamento (y): (9349,)\n",
      "Teste (X): (3117, 12)\n",
      "Teste (y): (3117,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando os tamanhos dos conjuntos de treinamento e teste\n",
    "print(f\"Treinamento (X): {X_train.shape}\")\n",
    "print(f\"Treinamento (y): {y_train.shape}\")\n",
    "print(f\"Teste (X): {X_test.shape}\")\n",
    "print(f\"Teste (y): {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo a coluna de sexo para binário\n",
    "X_train['sexo'] = X_train['sexo'].map({'M': 0, 'F': 1})\n",
    "X_test['sexo'] = X_test['sexo'].map({'M': 0, 'F': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo codificação one-hot para as colunas categóricas\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# Certificando-se de que ambas as divisões de treino e teste têm as mesmas colunas após a codificação one-hot\n",
    "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
    "for c in missing_cols:\n",
    "    X_test[c] = 0\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Conversão das colunas tipo bool para int\n",
    "X_train['posse_de_veiculo'] = X_train['posse_de_veiculo'].astype(int)\n",
    "X_train['posse_de_imovel'] = X_train['posse_de_imovel'].astype(int)\n",
    "X_test['posse_de_imovel'] = X_test['posse_de_imovel'].astype(int)\n",
    "X_train['mau'] = X_train['mau'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, R2: 0.2066\n",
      "Alpha: 0.001, R2: 0.2073\n",
      "Alpha: 0.005, R2: 0.2073\n",
      "Alpha: 0.01, R2: 0.2073\n",
      "Alpha: 0.05, R2: 0.2073\n",
      "Alpha: 0.1, R2: 0.2073\n"
     ]
    }
   ],
   "source": [
    "# Normalizar os dados antes\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Lista de valores alpha que você forneceu\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Inicializando uma lista para armazenar os resultados de R2\n",
    "r2_results = []\n",
    "\n",
    "# Loop por cada valor de alpha\n",
    "for alpha in alphas:\n",
    "    # Inicializando o modelo Ridge com o valor de alpha atual\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    \n",
    "    # Treinando o modelo com o conjunto de treinamento normalizado\n",
    "    ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Prevendo os valores da variável dependente na base de testes\n",
    "    y_pred = ridge.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculando o R2 para as previsões\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adicionando o R2 calculado à lista de resultados\n",
    "    r2_results.append(r2)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "for alpha, r2 in zip(alphas, r2_results):\n",
    "    print(f\"Alpha: {alpha}, R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A regularização não mostrou melhorias significativas no desempenho do modelo em comparação com a regressão linear simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeluc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.485e+08, tolerance: 2.156e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jeluc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.483e+08, tolerance: 2.156e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jeluc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.084e+08, tolerance: 2.156e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\jeluc\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.225e+07, tolerance: 2.156e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.001, R2: 0.2073\n",
      "Alpha: 0.005, R2: 0.2073\n",
      "Alpha: 0.01, R2: 0.2073\n",
      "Alpha: 0.05, R2: 0.2073\n",
      "Alpha: 0.1, R2: 0.2073\n",
      "Alpha: 0.5, R2: 0.2073\n",
      "Alpha: 1, R2: 0.2073\n",
      "Alpha: 10, R2: 0.2074\n"
     ]
    }
   ],
   "source": [
    "# Normalizar os dados antes\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Lista de valores alpha\n",
    "alphas = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10]\n",
    "\n",
    "# Inicializando uma lista para armazenar os resultados de R2\n",
    "r2_results_lasso = []\n",
    "\n",
    "# Loop por cada valor de alpha\n",
    "for alpha in alphas:\n",
    "    # Inicializando o modelo Lasso com o valor de alpha atual e max_iter de 15k\n",
    "    lasso = Lasso(alpha=alpha, max_iter=15000)\n",
    "    \n",
    "    # Treinando o modelo com o conjunto de treinamento normalizado\n",
    "    lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Prevendo os valores da variável dependente na base de testes\n",
    "    y_pred = lasso.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculando o R2 para as previsões\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Adicionando o R2 calculado à lista de resultados\n",
    "    r2_results_lasso.append(r2)\n",
    "\n",
    "# Imprimindo os resultados\n",
    "for alpha, r2 in zip(alphas, r2_results_lasso):\n",
    "    print(f\"Alpha: {alpha}, R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os valores R2 fornecidos:\n",
    "\n",
    "Ridge: O melhor R2 foi 0.2073 (com vários alphas).\n",
    "Lasso: O melhor R2 foi 0.2074 (com alpha = 10).\n",
    "Ambos os modelos fornecem valores muito próximos de R2. A diferença é mínima, mas, tecnicamente, o LASSO com alpha = 10 fornece um valor ligeiramente melhor de R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out = 0.05, verbose=True):\n",
    "    \"\"\" Implementa uma seleção stepwise para p-valores.\n",
    "        @param X: dataframe com os dados de entrada\n",
    "        @param y: variável dependente\n",
    "        @param initial_list: lista inicial de variáveis\n",
    "        @param threshold_in: valor de corte para incluir uma variável\n",
    "        @param threshold_out: valor de corte para remover uma variável\n",
    "        @return: lista de variáveis selecionadas\n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded, dtype='float64')\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add  tempo_emprego                  with p-value 0.0\n",
      "Add  sexo                           with p-value 5.6563e-125\n",
      "Add  tipo_renda_Assalariado         with p-value 1.57794e-20\n",
      "Add  idade                          with p-value 2.11629e-09\n",
      "Add  educacao_Superior completo     with p-value 9.12908e-11\n",
      "Add  posse_de_imovel                with p-value 9.32363e-05\n",
      "Add  tipo_residencia_Casa           with p-value 0.00161901\n",
      "Add  tipo_renda_Servidor público    with p-value 0.00306837\n",
      "Add  educacao_Pós graduação         with p-value 0.00568422\n",
      "R2 (stepwise): 0.2078\n"
     ]
    }
   ],
   "source": [
    "selected_features = stepwise_selection(X_train, y_train)\n",
    "\n",
    "# Treinar o modelo usando apenas as variáveis selecionadas\n",
    "model = sm.OLS(y_train, sm.add_constant(X_train[selected_features])).fit()\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "y_pred = model.predict(sm.add_constant(X_test[selected_features]))\n",
    "\n",
    "# Avaliar R2\n",
    "r2_stepwise = r2_score(y_test, y_pred)\n",
    "print(f\"R2 (stepwise): {r2_stepwise:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Todos os modelos são semelhantes para compararmos o R2. O modelo stepwise tem o valor mais alto, mas apenas marginalmente (0.2078 contra 0.2074 do modelo regularizado com alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suspeita sobre a variável 'idade' não ter uma relação linear\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "idade_transformed = poly.fit_transform(df[['idade']])\n",
    "\n",
    "# Adicionando as novas colunas ao dataframe\n",
    "df['idade'] = idade_transformed[:, 0]  # Esta é a coluna original\n",
    "df['idade^2'] = idade_transformed[:, 1]\n",
    "df['log_renda'] = np.log(df['renda'] + 1)  # Adicionamos 1 para evitar o log de 0\n",
    "df['renda_tempo_emprego'] = df['renda'] * df['tempo_emprego']\n",
    "df['renda_idade2'] = df['renda'] * df['idade^2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checando se há valores infinitos em renda\n",
    "print((np.isinf(df['renda'])).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora tratando outliers e selecionando apenas colunas numéricas\n",
    "numeric_cols = df.select_dtypes(include=[np.number])\n",
    "\n",
    "Q1 = numeric_cols.quantile(0.25)\n",
    "Q3 = numeric_cols.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Para cada coluna numérica, remova os outliers\n",
    "for col in numeric_cols.columns:\n",
    "    df = df[~((df[col] < (Q1[col] - 1.5 * IQR[col])) | (df[col] > (Q3[col] + 1.5 * IQR[col])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garantindo que as variáveis estejam em uma escala similar\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro Quadrático Médio (MSE): 17998834.18\n",
      "Erro Quadrático Médio da Raiz (RMSE): 4242.50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Treinando o modelo\n",
    "regressor = RandomForestRegressor()  # Usando os hiperparâmetros padrão inicialmente\n",
    "regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Avaliando o modelo no conjunto de teste\n",
    "y_pred = regressor.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Erro Quadrático Médio (MSE): {mse:.2f}\")\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Erro Quadrático Médio da Raiz (RMSE): {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 da Árvore de Regressão: 0.18\n"
     ]
    }
   ],
   "source": [
    "# 1. Importando o regressor da árvore de decisão\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# 2. Criando uma instância do regressor\n",
    "tree_regressor = DecisionTreeRegressor()\n",
    "\n",
    "# 3. Treinando o regressor com os dados de treinamento\n",
    "tree_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Avaliando o modelo no conjunto de testes\n",
    "y_pred_tree = tree_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Calculando R^2\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"R^2 da Árvore de Regressão: {r2_tree:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Ridge e Lasso (ambos com R2 de cerca de 0.207) estão melhores do que a Árvore de Regressão com R2 de 0.17."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
